{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f984d698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/shaswata/.local/lib/python3.9/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /u/shaswata/.local/lib/python3.9/site-packages/torch_scatter/_scatter_cpu.so: undefined symbol: _ZN5torch8autograd13_wrap_outputsERKSt6vectorIN2at6TensorESaIS3_EERKSt13unordered_setIPN3c1010TensorImplESt4hashISB_ESt8equal_toISB_ESaISB_EESJ_NS9_8ArrayRefINS9_8optionalIS3_EEEERKSt10shared_ptrINS0_4NodeEESt8functionIFS5_S5_S5_EE\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/u/shaswata/.local/lib/python3.9/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /u/shaswata/.local/lib/python3.9/site-packages/torch_cluster/_graclus_cpu.so: undefined symbol: _ZN2at4_ops8randperm4callElN3c108optionalINS2_10ScalarTypeEEENS3_INS2_6LayoutEEENS3_INS2_6DeviceEEENS3_IbEE\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/u/shaswata/.local/lib/python3.9/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /u/shaswata/.local/lib/python3.9/site-packages/torch_spline_conv/_basis_cpu.so: undefined symbol: _ZN5torch8autograd13_wrap_outputsERKSt6vectorIN2at6TensorESaIS3_EERKSt13unordered_setIPN3c1010TensorImplESt4hashISB_ESt8equal_toISB_ESaISB_EESJ_NS9_8ArrayRefINS9_8optionalIS3_EEEERKSt10shared_ptrINS0_4NodeEESt8functionIFS5_S5_S5_EE\n",
      "  warnings.warn(\n",
      "/u/shaswata/.local/lib/python3.9/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /u/shaswata/.local/lib/python3.9/site-packages/torch_sparse/_spmm_cpu.so: undefined symbol: _ZN5torch8autograd13_wrap_outputsERKSt6vectorIN2at6TensorESaIS3_EERKSt13unordered_setIPN3c1010TensorImplESt4hashISB_ESt8equal_toISB_ESaISB_EESJ_NS9_8ArrayRefINS9_8optionalIS3_EEEERKSt10shared_ptrINS0_4NodeEESt8functionIFS5_S5_S5_EE\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora()\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Epoch 000, Loss: 1.9538\n",
      "Epoch 010, Loss: 0.6884\n",
      "Epoch 020, Loss: 0.1508\n",
      "Epoch 030, Loss: 0.0272\n",
      "Epoch 040, Loss: 0.0087\n",
      "Model trained successfully!\n",
      "Test Accuracy: 0.7790\n",
      "\n",
      "Explaining prediction for node 42...\n",
      "Explanation for node 42:\n",
      "Node importance scores shape: torch.Size([2708, 1433])\n",
      "Edge importance scores shape: torch.Size([10556])\n",
      "Top 5 most important features for node 42:\n",
      "  Feature 421: 0.6658\n",
      "  Feature 725: 0.6657\n",
      "  Feature 702: 0.6574\n",
      "  Feature 416: 0.6499\n",
      "  Feature 653: 0.6472\n",
      "\n",
      "Explanation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric.nn\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Load a dataset (e.g., Cora)\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "print(f\"Dataset: {dataset}\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "\n",
    "# Create a GNN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = torch_geometric.nn.GCNConv(in_channels, 16)\n",
    "        self.conv2 = torch_geometric.nn.GCNConv(16, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = GCN(dataset.num_node_features, dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model (reduced epochs for faster execution)\n",
    "model.train()\n",
    "num_epochs = 50  # Reduced from 200\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = torch.nn.CrossEntropyLoss()(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "\n",
    "# Evaluate the model quickly\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(data.x, data.edge_index).argmax(dim=-1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).float().mean()\n",
    "    print(f'Test Accuracy: {correct:.4f}')\n",
    "\n",
    "# Initialize the explainer using the new API\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=50),  # Reduced epochs for faster explanation\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Explain a prediction\n",
    "node_idx = 42  # Example node for explanation\n",
    "print(f\"\\nExplaining prediction for node {node_idx}...\")\n",
    "explanation = explainer(data.x, data.edge_index, index=node_idx)\n",
    "\n",
    "print(f\"Explanation for node {node_idx}:\")\n",
    "print(f\"Node importance scores shape: {explanation.node_mask.shape if explanation.node_mask is not None else 'None'}\")\n",
    "print(f\"Edge importance scores shape: {explanation.edge_mask.shape if explanation.edge_mask is not None else 'None'}\")\n",
    "\n",
    "# Show some basic info about the explanation\n",
    "if explanation.node_mask is not None:\n",
    "    print(f\"Top 5 most important features for node {node_idx}:\")\n",
    "    top_features = explanation.node_mask[node_idx].argsort(descending=True)[:5]\n",
    "    for i, feat_idx in enumerate(top_features):\n",
    "        print(f\"  Feature {feat_idx}: {explanation.node_mask[node_idx][feat_idx]:.4f}\")\n",
    "\n",
    "print(\"\\nExplanation completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db17a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "# Create a visualization of the explanation\n",
    "def visualize_explanation(data, explanation, node_idx, subset_size=30):\n",
    "    \"\"\"\n",
    "    Visualize the graph explanation with highlighted important nodes and edges\n",
    "    \"\"\"\n",
    "    # Convert to NetworkX graph for easier visualization\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    \n",
    "    # Get the subgraph around the explained node for better visualization\n",
    "    # Find neighbors within 2 hops of the target node\n",
    "    neighbors = set([node_idx])\n",
    "    for _ in range(2):  # 2-hop neighborhood\n",
    "        new_neighbors = set()\n",
    "        for node in neighbors:\n",
    "            if node in G:\n",
    "                new_neighbors.update(G.neighbors(node))\n",
    "        neighbors.update(new_neighbors)\n",
    "    \n",
    "    # Limit the size for better visualization\n",
    "    neighbors = list(neighbors)[:subset_size]\n",
    "    subgraph = G.subgraph(neighbors)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Get positions for nodes\n",
    "    pos = nx.spring_layout(subgraph, k=1, iterations=50)\n",
    "    \n",
    "    # Prepare node colors based on importance\n",
    "    node_colors = []\n",
    "    node_sizes = []\n",
    "    \n",
    "    for node in subgraph.nodes():\n",
    "        if explanation.node_mask is not None and node < len(explanation.node_mask):\n",
    "            # Use the sum of feature importance for this node\n",
    "            importance = explanation.node_mask[node].sum().item()\n",
    "            # Normalize importance for color mapping\n",
    "            importance = max(0, min(1, (importance + 1) / 2))  # Normalize to [0, 1]\n",
    "        else:\n",
    "            importance = 0.1\n",
    "        \n",
    "        if node == node_idx:\n",
    "            node_colors.append('red')  # Target node in red\n",
    "            node_sizes.append(800)\n",
    "        else:\n",
    "            # Color based on importance (blue to yellow gradient)\n",
    "            node_colors.append(plt.cm.RdYlBu_r(importance))\n",
    "            node_sizes.append(300 + importance * 300)\n",
    "    \n",
    "    # Prepare edge colors and widths based on importance\n",
    "    edge_colors = []\n",
    "    edge_widths = []\n",
    "    \n",
    "    if explanation.edge_mask is not None:\n",
    "        # Create edge index mapping for the subgraph\n",
    "        edge_mapping = {}\n",
    "        for i, (u, v) in enumerate(data.edge_index.t().tolist()):\n",
    "            if u in neighbors and v in neighbors:\n",
    "                edge_mapping[(u, v)] = i\n",
    "                edge_mapping[(v, u)] = i  # For undirected graphs\n",
    "        \n",
    "        for edge in subgraph.edges():\n",
    "            u, v = edge\n",
    "            if (u, v) in edge_mapping:\n",
    "                edge_idx = edge_mapping[(u, v)]\n",
    "                if edge_idx < len(explanation.edge_mask):\n",
    "                    importance = explanation.edge_mask[edge_idx].item()\n",
    "                    importance = max(0, min(1, (importance + 1) / 2))  # Normalize\n",
    "                else:\n",
    "                    importance = 0.1\n",
    "            else:\n",
    "                importance = 0.1\n",
    "            \n",
    "            edge_colors.append(plt.cm.Reds(importance))\n",
    "            edge_widths.append(0.5 + importance * 3)\n",
    "    else:\n",
    "        edge_colors = ['gray'] * len(subgraph.edges())\n",
    "        edge_widths = [1] * len(subgraph.edges())\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw_networkx_edges(subgraph, pos, edge_color=edge_colors, width=edge_widths, alpha=0.7)\n",
    "    nx.draw_networkx_nodes(subgraph, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8)\n",
    "    \n",
    "    # Add labels for important nodes\n",
    "    important_nodes = {node_idx: str(node_idx)}\n",
    "    nx.draw_networkx_labels(subgraph, pos, important_nodes, font_size=12, font_weight='bold')\n",
    "    \n",
    "    plt.title(f'Graph Explanation for Node {node_idx}\\n'\n",
    "              f'Red node = target, Color intensity = importance', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Add colorbar for node importance\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.RdYlBu_r, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=plt.gca(), shrink=0.6)\n",
    "    cbar.set_label('Node Importance', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the explanation\n",
    "print(f\"Visualizing explanation for node {node_idx}...\")\n",
    "visualize_explanation(data, explanation, node_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6fa50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional visualization: Feature importance for the explained node\n",
    "def plot_feature_importance(explanation, node_idx, top_k=10):\n",
    "    \"\"\"\n",
    "    Plot the top-k most important features for the explained node\n",
    "    \"\"\"\n",
    "    if explanation.node_mask is None:\n",
    "        print(\"No node feature importance available\")\n",
    "        return\n",
    "    \n",
    "    # Get feature importance for the target node\n",
    "    node_importance = explanation.node_mask[node_idx]\n",
    "    \n",
    "    # Get top-k features\n",
    "    top_indices = node_importance.argsort(descending=True)[:top_k]\n",
    "    top_values = node_importance[top_indices]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Create bar plot\n",
    "    bars = plt.bar(range(len(top_values)), top_values.detach().numpy(), \n",
    "                   color='skyblue', alpha=0.7, edgecolor='navy')\n",
    "    \n",
    "    # Highlight the most important feature\n",
    "    if len(bars) > 0:\n",
    "        bars[0].set_color('orange')\n",
    "    \n",
    "    plt.xlabel('Feature Index', fontsize=12)\n",
    "    plt.ylabel('Importance Score', fontsize=12)\n",
    "    plt.title(f'Top {top_k} Most Important Features for Node {node_idx}', fontsize=14)\n",
    "    plt.xticks(range(len(top_values)), [f'F{idx.item()}' for idx in top_indices])\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, value) in enumerate(zip(bars, top_values)):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "                f'{value:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot feature importance\n",
    "plot_feature_importance(explanation, node_idx, top_k=min(10, data.x.shape[1]))\n",
    "\n",
    "# Print detailed explanation statistics\n",
    "print(f\"\\n=== Detailed Explanation Analysis ===\")\n",
    "print(f\"Target node: {node_idx}\")\n",
    "print(f\"True label: {data.y[node_idx].item()}\")\n",
    "\n",
    "# Get model prediction for this node\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    pred_label = logits[node_idx].argmax().item()\n",
    "    confidence = torch.softmax(logits[node_idx], dim=0).max().item()\n",
    "\n",
    "print(f\"Predicted label: {pred_label}\")\n",
    "print(f\"Prediction confidence: {confidence:.4f}\")\n",
    "print(f\"Prediction correct: {pred_label == data.y[node_idx].item()}\")\n",
    "\n",
    "if explanation.node_mask is not None:\n",
    "    print(f\"\\nNode feature importance:\")\n",
    "    print(f\"  Shape: {explanation.node_mask.shape}\")\n",
    "    print(f\"  Mean importance: {explanation.node_mask[node_idx].mean():.4f}\")\n",
    "    print(f\"  Max importance: {explanation.node_mask[node_idx].max():.4f}\")\n",
    "    print(f\"  Min importance: {explanation.node_mask[node_idx].min():.4f}\")\n",
    "\n",
    "if explanation.edge_mask is not None:\n",
    "    print(f\"\\nEdge importance:\")\n",
    "    print(f\"  Shape: {explanation.edge_mask.shape}\")\n",
    "    print(f\"  Mean importance: {explanation.edge_mask.mean():.4f}\")\n",
    "    print(f\"  Max importance: {explanation.edge_mask.max():.4f}\")\n",
    "    print(f\"  Min importance: {explanation.edge_mask.min():.4f}\")\n",
    "\n",
    "# Show the most important neighboring nodes\n",
    "if explanation.node_mask is not None:\n",
    "    print(f\"\\nMost important neighboring nodes (within 1-hop):\")\n",
    "    edge_index = data.edge_index\n",
    "    neighbors = edge_index[1][edge_index[0] == node_idx].unique()\n",
    "    \n",
    "    if len(neighbors) > 0:\n",
    "        neighbor_importance = []\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor < len(explanation.node_mask):\n",
    "                importance = explanation.node_mask[neighbor].sum().item()\n",
    "                neighbor_importance.append((neighbor.item(), importance))\n",
    "        \n",
    "        # Sort by importance\n",
    "        neighbor_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for i, (neighbor, importance) in enumerate(neighbor_importance[:5]):\n",
    "            print(f\"  Node {neighbor}: importance = {importance:.4f}, label = {data.y[neighbor].item()}\")\n",
    "    else:\n",
    "        print(\"  No direct neighbors found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChemProp Environment",
   "language": "python",
   "name": "chemprop_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
