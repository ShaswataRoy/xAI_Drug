{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82c061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "explain_benchmarks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea92d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "This script computes sparsity and fidelity benchmarks for GNN models\n",
    "trained on molecular datasets like TOX21 using PyTorch Geometric.\n",
    "It supports GNNExplainer and Integrated Gradients (Captum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a573d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.explain import GNNExplainer\n",
    "from captum.attr import IntegratedGradients\n",
    "from torch_geometric.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholder functions\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load a trained PyTorch model\"\"\"\n",
    "    model = torch.load(model_path)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24716b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_name, batch_size=32):\n",
    "    \"\"\"Load dataset (placeholder)\"\"\"\n",
    "    # Replace with actual data loading logic\n",
    "    from torch_geometric.datasets import Tox21\n",
    "    dataset = Tox21(root='./data', task=dataset_name)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a80a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gnnexplainer_benchmark(model, loader, device, output_dir):\n",
    "    explainer = GNNExplainer(model, epochs=200, return_type='logits')\n",
    "    sparsity_results = []\n",
    "    fidelity_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a08c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        for j in range(batch.num_graphs):\n",
    "            graph = batch[j]\n",
    "            pred_full = model(graph.x, graph.edge_index, batch.batch[j].unsqueeze(0))\n",
    "            node_feat_mask, edge_mask = explainer.explain_graph(graph.x, graph.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we would apply masking and recompute predictions\n",
    "            # Compute sparsity, fidelity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_results.append({\n",
    "                'graph_idx': i,\n",
    "                'sparsity': 0.0,  # Replace with actual\n",
    "                'auc_drop': 0.0   # Replace with actual\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a68a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelity_results.append({\n",
    "                'graph_idx': i,\n",
    "                'fidelity': 0.0   # Replace with actual\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sparsity_results).to_csv(os.path.join(output_dir, 'gnnexplainer_sparsity.csv'), index=False)\n",
    "    pd.DataFrame(fidelity_results).to_csv(os.path.join(output_dir, 'gnnexplainer_fidelity.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47435e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_integrated_gradients(model, loader, device, output_dir):\n",
    "    ig = IntegratedGradients(model)\n",
    "    fidelity_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17662cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        input = batch.x.requires_grad_()\n",
    "        target = batch.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4cdcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions, delta = ig.attribute(inputs=input,\n",
    "                                           target=target,\n",
    "                                           additional_forward_args=(batch.edge_index,),\n",
    "                                           return_convergence_delta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff08af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply attribution mask, recompute predictions\n",
    "        # Compute fidelity or infidelity metrics\n",
    "        fidelity_results.append({\n",
    "            'graph_idx': i,\n",
    "            'fidelity': 0.0  # Replace with actual\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95991884",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fidelity_results).to_csv(os.path.join(output_dir, 'integrated_gradients_fidelity.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_path', type=str, required=True)\n",
    "    parser.add_argument('--dataset', type=str, default='hiv')\n",
    "    parser.add_argument('--outdir', type=str, default='./benchmarks')\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eedbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(args.outdir, exist_ok=True)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = load_model(args.model_path).to(device)\n",
    "    loader = load_data(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gnnexplainer_benchmark(model, loader, device, args.outdir)\n",
    "    compute_integrated_gradients(model, loader, device, args.outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
